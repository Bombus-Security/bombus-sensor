input {
        beats {
		port => 5044
        }
}

# 01-Jul-2020: !:NOTE:! For now we are going to do all processing and 
# anonymization on the remote side. If we do move to local 
# processing than we'll fork the output.

# 01-Jul-2020: !:NOTE:! Filters to apply
# Split logs into different topics: syslog, wazuh, zeek
filter {
	clone {
		clones => ['anon', 'non-anon']
	}

	if [type] == "anon" {
		mutate { add_field => { "dataset" => "%{[fileset][name]}" } }
				
		mutate { remove_field => ["ecs", "input", "log", "tags", "service", "container", "@version", "fileset", "event"] }
	}
}

output {
	#stdout { codec => rubydebug { metadata => true } }
	if [type] == "non-anon" {
		elasticsearch {
			hosts => ["http://es01:9200"]
			index => "filebeat-%{+yyyy-MM-dd}"
		}
	}

	if [type] == "anon" {
		kafka {
			codec => json
			bootstrap_servers => "172.16.3.129:9092"
			client_id => "sensor01"
# 01-Jul-2020: !:TODO:! Need to create and use unique sensor names
			topic_id => "%{[dataset]}"
		}
	}
}
